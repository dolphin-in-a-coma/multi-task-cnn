{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled3.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Install the package"
      ],
      "metadata": {
        "id": "8mFcCCzayMTs"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pNLJK0Zmk853",
        "outputId": "fbce7a67-4c8b-43a3-b46d-14af148a3b10"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting git+https://github.com/dolphin-in-a-coma/multi-task-cnn-eeg-emotion.git\n",
            "  Cloning https://github.com/dolphin-in-a-coma/multi-task-cnn-eeg-emotion.git to /tmp/pip-req-build-hmyddcky\n",
            "  Running command git clone -q https://github.com/dolphin-in-a-coma/multi-task-cnn-eeg-emotion.git /tmp/pip-req-build-hmyddcky\n",
            "Building wheels for collected packages: eegemotion\n",
            "  Building wheel for eegemotion (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for eegemotion: filename=eegemotion-1.0-py3-none-any.whl size=9170 sha256=4f2b9e77553a4ded57ef91f958f354cddb846740842fbdcd4bc8978b7338e05c\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-yo_7unqb/wheels/4b/55/5a/451c23785b0102aa988bf281121575019f779f155b12f77bec\n",
            "Successfully built eegemotion\n",
            "Installing collected packages: eegemotion\n",
            "Successfully installed eegemotion-1.0\n"
          ]
        }
      ],
      "source": [
        "!pip install git+https://github.com/dolphin-in-a-coma/multi-task-cnn-eeg-emotion.git"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        ""
      ],
      "metadata": {
        "id": "PNDeMjtdyMMM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Connect to Google Drive\n",
        "Needed only if you work with Colab \n"
      ],
      "metadata": {
        "id": "b30VgF5NuzND"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os, sys\n",
        "from google.colab import drive\n",
        "\n",
        "DRIVE_DATA_PATH = 'data/'\n",
        "\n",
        "\n",
        "drive.mount('/content/drive')\n",
        "data_path = '/content/data'\n",
        "os.symlink(os.path.join('/content/drive/My Drive/', DRIVE_DATA_PATH), data_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L_HhCPHQurTg",
        "outputId": "8c66bebc-8cf5-462f-999e-8f830b760295"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Specify arguments"
      ],
      "metadata": {
        "id": "VTb4zGkyybQz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# specify dataset and model dirs\n",
        "dataset_dir = data_path # path of the folder with PSD_s and DE_s files\n",
        "model_dir = data_path # path where the model and metrics will be stored "
      ],
      "metadata": {
        "id": "1_QlO1yA1CzO"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from eegemotion.data_load import load_data \n",
        "from eegemotion.train import train\n",
        "\n",
        "img_size = img_rows, img_cols, num_chan = 8, 9, 8 # matrix shape of input data\n",
        "number_of_inputs=2 # how many frames is taken into account during one pass\n",
        "\n",
        "features_type='multi' # 'PSD', 'DE' or 'multi' \n",
        "num_classes=2 # number of classes of input data\n",
        "frames_per_subject=4800 # how many frames per one subject\n",
        "seed=7 # random seed\n",
        "\n",
        "dropout_rate=.2\n",
        "model_name='MT_CNN' # will be a filename part\n",
        "lr_decay_factor=0.5 # multiplixity factor of lr, where it's stucked in th plateu\n",
        "lr_decay_patience=5 # how many epochs without prgress before lr_decay\n",
        "epochs_n=200 # maximum number of epochs\n",
        "verbose=0 # 0, 1 or 2\n",
        "\n",
        "# НЕ ХВАТАЕТ MULTI_TASK и файн-тюн\n",
        "# и еще чего-то не хватает\n",
        "\n",
        "short_names = ('01', '02', '03', '04', '05', '06', '07', '08', \n",
        "              '09', '10', '11', '12', '13', '14', '15', '16', \n",
        "              '17', '18', '19', '20', '21', '22', '23', '24',\n",
        "              '25', '26', '27', '28', '29', '30', '31', '32') # наверное нужно поменять"
      ],
      "metadata": {
        "id": "gRrTuDkGlEqn"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load data and prepare for training"
      ],
      "metadata": {
        "id": "LgJnxjRV31Cu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y_a_all_subject, y_v_all_subject, x_all_subject, all_subject_id =\\\n",
        "    load_data(dataset_dir, short_names, img_size, number_of_inputs, features_type, num_classes, frames_per_subject, seed)"
      ],
      "metadata": {
        "id": "Q8YUZtXiqCvR"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train the model"
      ],
      "metadata": {
        "id": "aq0xC7NO36gA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train(x_all_subject, y_a_all_subject, y_v_all_subject, all_subject_id, short_names,\n",
        "      dropout_rate, number_of_inputs, model_dir, model_name, img_size, lr_decay_factor,\n",
        "      lr_decay_patience, epochs_n, seed, verbose)\n",
        "\n",
        "# какая-то залупа с памятью"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pLQg9rTmtseU",
        "outputId": "43fc72ba-f5e5-4d62-ff7a-5c3d27ad4e29"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "957/960 [============================>.] - ETA: 0s - loss: 1.2880 - out_v_loss: 0.6529 - out_a_loss: 0.6351 - out_v_accuracy: 0.6382 - out_a_accuracy: 0.6573"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/engine/functional.py:1410: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
            "  layer_config = serialize_layer_fn(layer)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "960/960 [==============================] - 29s 19ms/step - loss: 1.2873 - out_v_loss: 0.6526 - out_a_loss: 0.6347 - out_v_accuracy: 0.6384 - out_a_accuracy: 0.6576 - val_loss: 1.0430 - val_out_v_loss: 0.5398 - val_out_a_loss: 0.5032 - val_out_v_accuracy: 0.7255 - val_out_a_accuracy: 0.7492 - lr: 0.0010\n",
            "Epoch 2/200\n",
            "960/960 [==============================] - 18s 19ms/step - loss: 0.9876 - out_v_loss: 0.4994 - out_a_loss: 0.4882 - out_v_accuracy: 0.7490 - out_a_accuracy: 0.7561 - val_loss: 0.8103 - val_out_v_loss: 0.4141 - val_out_a_loss: 0.3962 - val_out_v_accuracy: 0.8062 - val_out_a_accuracy: 0.8110 - lr: 0.0010\n",
            "Epoch 3/200\n",
            "960/960 [==============================] - 19s 20ms/step - loss: 0.8225 - out_v_loss: 0.4150 - out_a_loss: 0.4075 - out_v_accuracy: 0.8019 - out_a_accuracy: 0.8052 - val_loss: 0.6376 - val_out_v_loss: 0.3262 - val_out_a_loss: 0.3114 - val_out_v_accuracy: 0.8535 - val_out_a_accuracy: 0.8589 - lr: 0.0010\n",
            "Epoch 4/200\n",
            "960/960 [==============================] - 20s 21ms/step - loss: 0.7157 - out_v_loss: 0.3606 - out_a_loss: 0.3551 - out_v_accuracy: 0.8316 - out_a_accuracy: 0.8345 - val_loss: 0.5864 - val_out_v_loss: 0.2891 - val_out_a_loss: 0.2973 - val_out_v_accuracy: 0.8763 - val_out_a_accuracy: 0.8643 - lr: 0.0010\n",
            "Epoch 5/200\n",
            "960/960 [==============================] - 19s 20ms/step - loss: 0.6358 - out_v_loss: 0.3208 - out_a_loss: 0.3150 - out_v_accuracy: 0.8535 - out_a_accuracy: 0.8561 - val_loss: 0.4932 - val_out_v_loss: 0.2474 - val_out_a_loss: 0.2458 - val_out_v_accuracy: 0.8916 - val_out_a_accuracy: 0.8886 - lr: 0.0010\n",
            "Epoch 6/200\n",
            "960/960 [==============================] - 20s 21ms/step - loss: 0.5828 - out_v_loss: 0.2949 - out_a_loss: 0.2879 - out_v_accuracy: 0.8671 - out_a_accuracy: 0.8702 - val_loss: 0.4657 - val_out_v_loss: 0.2411 - val_out_a_loss: 0.2246 - val_out_v_accuracy: 0.8980 - val_out_a_accuracy: 0.9022 - lr: 0.0010\n",
            "Epoch 7/200\n",
            "960/960 [==============================] - 20s 21ms/step - loss: 0.5406 - out_v_loss: 0.2739 - out_a_loss: 0.2667 - out_v_accuracy: 0.8769 - out_a_accuracy: 0.8806 - val_loss: 0.4369 - val_out_v_loss: 0.2200 - val_out_a_loss: 0.2169 - val_out_v_accuracy: 0.9057 - val_out_a_accuracy: 0.9081 - lr: 0.0010\n",
            "Epoch 8/200\n",
            "960/960 [==============================] - 20s 21ms/step - loss: 0.5110 - out_v_loss: 0.2586 - out_a_loss: 0.2525 - out_v_accuracy: 0.8840 - out_a_accuracy: 0.8883 - val_loss: 0.4085 - val_out_v_loss: 0.2153 - val_out_a_loss: 0.1932 - val_out_v_accuracy: 0.9087 - val_out_a_accuracy: 0.9178 - lr: 0.0010\n",
            "Epoch 9/200\n",
            "960/960 [==============================] - 19s 20ms/step - loss: 0.4810 - out_v_loss: 0.2428 - out_a_loss: 0.2382 - out_v_accuracy: 0.8931 - out_a_accuracy: 0.8951 - val_loss: 0.3779 - val_out_v_loss: 0.1934 - val_out_a_loss: 0.1844 - val_out_v_accuracy: 0.9182 - val_out_a_accuracy: 0.9227 - lr: 0.0010\n",
            "Epoch 10/200\n",
            "960/960 [==============================] - 20s 21ms/step - loss: 0.4490 - out_v_loss: 0.2261 - out_a_loss: 0.2229 - out_v_accuracy: 0.9005 - out_a_accuracy: 0.9021 - val_loss: 0.3599 - val_out_v_loss: 0.1807 - val_out_a_loss: 0.1793 - val_out_v_accuracy: 0.9266 - val_out_a_accuracy: 0.9228 - lr: 0.0010\n",
            "Epoch 11/200\n",
            "960/960 [==============================] - 19s 20ms/step - loss: 0.4292 - out_v_loss: 0.2164 - out_a_loss: 0.2128 - out_v_accuracy: 0.9056 - out_a_accuracy: 0.9083 - val_loss: 0.3432 - val_out_v_loss: 0.1734 - val_out_a_loss: 0.1698 - val_out_v_accuracy: 0.9288 - val_out_a_accuracy: 0.9303 - lr: 0.0010\n",
            "Epoch 12/200\n",
            "960/960 [==============================] - 19s 20ms/step - loss: 0.4105 - out_v_loss: 0.2065 - out_a_loss: 0.2039 - out_v_accuracy: 0.9108 - out_a_accuracy: 0.9108 - val_loss: 0.3488 - val_out_v_loss: 0.1743 - val_out_a_loss: 0.1745 - val_out_v_accuracy: 0.9274 - val_out_a_accuracy: 0.9268 - lr: 0.0010\n",
            "Epoch 13/200\n",
            "960/960 [==============================] - 19s 20ms/step - loss: 0.4006 - out_v_loss: 0.2029 - out_a_loss: 0.1977 - out_v_accuracy: 0.9126 - out_a_accuracy: 0.9150 - val_loss: 0.3205 - val_out_v_loss: 0.1602 - val_out_a_loss: 0.1604 - val_out_v_accuracy: 0.9326 - val_out_a_accuracy: 0.9312 - lr: 0.0010\n",
            "Epoch 14/200\n",
            "960/960 [==============================] - 19s 20ms/step - loss: 0.3827 - out_v_loss: 0.1924 - out_a_loss: 0.1902 - out_v_accuracy: 0.9172 - out_a_accuracy: 0.9181 - val_loss: 0.3048 - val_out_v_loss: 0.1564 - val_out_a_loss: 0.1484 - val_out_v_accuracy: 0.9365 - val_out_a_accuracy: 0.9357 - lr: 0.0010\n",
            "Epoch 15/200\n",
            "960/960 [==============================] - 19s 20ms/step - loss: 0.3625 - out_v_loss: 0.1821 - out_a_loss: 0.1804 - out_v_accuracy: 0.9219 - out_a_accuracy: 0.9233 - val_loss: 0.3092 - val_out_v_loss: 0.1590 - val_out_a_loss: 0.1502 - val_out_v_accuracy: 0.9335 - val_out_a_accuracy: 0.9350 - lr: 0.0010\n",
            "Epoch 16/200\n",
            "960/960 [==============================] - 18s 19ms/step - loss: 0.3569 - out_v_loss: 0.1796 - out_a_loss: 0.1773 - out_v_accuracy: 0.9231 - out_a_accuracy: 0.9243 - val_loss: 0.3078 - val_out_v_loss: 0.1556 - val_out_a_loss: 0.1522 - val_out_v_accuracy: 0.9380 - val_out_a_accuracy: 0.9368 - lr: 0.0010\n",
            "Epoch 17/200\n",
            "960/960 [==============================] - 19s 20ms/step - loss: 0.3417 - out_v_loss: 0.1720 - out_a_loss: 0.1697 - out_v_accuracy: 0.9269 - out_a_accuracy: 0.9274 - val_loss: 0.2936 - val_out_v_loss: 0.1468 - val_out_a_loss: 0.1468 - val_out_v_accuracy: 0.9417 - val_out_a_accuracy: 0.9403 - lr: 0.0010\n",
            "Epoch 18/200\n",
            "960/960 [==============================] - 20s 21ms/step - loss: 0.3323 - out_v_loss: 0.1669 - out_a_loss: 0.1654 - out_v_accuracy: 0.9285 - out_a_accuracy: 0.9299 - val_loss: 0.2769 - val_out_v_loss: 0.1354 - val_out_a_loss: 0.1415 - val_out_v_accuracy: 0.9462 - val_out_a_accuracy: 0.9426 - lr: 0.0010\n",
            "Epoch 19/200\n",
            "960/960 [==============================] - 18s 19ms/step - loss: 0.3217 - out_v_loss: 0.1631 - out_a_loss: 0.1586 - out_v_accuracy: 0.9310 - out_a_accuracy: 0.9327 - val_loss: 0.2807 - val_out_v_loss: 0.1451 - val_out_a_loss: 0.1356 - val_out_v_accuracy: 0.9419 - val_out_a_accuracy: 0.9430 - lr: 0.0010\n",
            "Epoch 20/200\n",
            "960/960 [==============================] - 20s 21ms/step - loss: 0.3120 - out_v_loss: 0.1572 - out_a_loss: 0.1548 - out_v_accuracy: 0.9330 - out_a_accuracy: 0.9342 - val_loss: 0.2612 - val_out_v_loss: 0.1321 - val_out_a_loss: 0.1291 - val_out_v_accuracy: 0.9451 - val_out_a_accuracy: 0.9464 - lr: 0.0010\n",
            "Epoch 21/200\n",
            "960/960 [==============================] - 18s 19ms/step - loss: 0.3051 - out_v_loss: 0.1546 - out_a_loss: 0.1506 - out_v_accuracy: 0.9341 - out_a_accuracy: 0.9364 - val_loss: 0.2698 - val_out_v_loss: 0.1383 - val_out_a_loss: 0.1315 - val_out_v_accuracy: 0.9449 - val_out_a_accuracy: 0.9463 - lr: 0.0010\n",
            "Epoch 22/200\n",
            "960/960 [==============================] - 19s 20ms/step - loss: 0.2980 - out_v_loss: 0.1508 - out_a_loss: 0.1472 - out_v_accuracy: 0.9370 - out_a_accuracy: 0.9376 - val_loss: 0.2642 - val_out_v_loss: 0.1359 - val_out_a_loss: 0.1283 - val_out_v_accuracy: 0.9447 - val_out_a_accuracy: 0.9464 - lr: 0.0010\n",
            "Epoch 23/200\n",
            "960/960 [==============================] - 19s 20ms/step - loss: 0.2905 - out_v_loss: 0.1475 - out_a_loss: 0.1430 - out_v_accuracy: 0.9376 - out_a_accuracy: 0.9397 - val_loss: 0.2564 - val_out_v_loss: 0.1295 - val_out_a_loss: 0.1269 - val_out_v_accuracy: 0.9477 - val_out_a_accuracy: 0.9486 - lr: 0.0010\n",
            "Epoch 24/200\n",
            "960/960 [==============================] - 20s 21ms/step - loss: 0.2827 - out_v_loss: 0.1429 - out_a_loss: 0.1397 - out_v_accuracy: 0.9403 - out_a_accuracy: 0.9417 - val_loss: 0.2522 - val_out_v_loss: 0.1264 - val_out_a_loss: 0.1258 - val_out_v_accuracy: 0.9497 - val_out_a_accuracy: 0.9495 - lr: 0.0010\n",
            "Epoch 25/200\n",
            "960/960 [==============================] - 19s 20ms/step - loss: 0.2707 - out_v_loss: 0.1372 - out_a_loss: 0.1335 - out_v_accuracy: 0.9425 - out_a_accuracy: 0.9430 - val_loss: 0.2487 - val_out_v_loss: 0.1242 - val_out_a_loss: 0.1245 - val_out_v_accuracy: 0.9499 - val_out_a_accuracy: 0.9488 - lr: 0.0010\n",
            "Epoch 26/200\n",
            "960/960 [==============================] - 19s 20ms/step - loss: 0.2689 - out_v_loss: 0.1373 - out_a_loss: 0.1315 - out_v_accuracy: 0.9430 - out_a_accuracy: 0.9457 - val_loss: 0.2438 - val_out_v_loss: 0.1209 - val_out_a_loss: 0.1229 - val_out_v_accuracy: 0.9516 - val_out_a_accuracy: 0.9497 - lr: 0.0010\n",
            "Epoch 27/200\n",
            "960/960 [==============================] - 19s 20ms/step - loss: 0.2642 - out_v_loss: 0.1318 - out_a_loss: 0.1324 - out_v_accuracy: 0.9457 - out_a_accuracy: 0.9448 - val_loss: 0.2379 - val_out_v_loss: 0.1204 - val_out_a_loss: 0.1175 - val_out_v_accuracy: 0.9508 - val_out_a_accuracy: 0.9518 - lr: 0.0010\n",
            "Epoch 28/200\n",
            "960/960 [==============================] - 18s 19ms/step - loss: 0.2617 - out_v_loss: 0.1310 - out_a_loss: 0.1307 - out_v_accuracy: 0.9454 - out_a_accuracy: 0.9439 - val_loss: 0.2398 - val_out_v_loss: 0.1201 - val_out_a_loss: 0.1197 - val_out_v_accuracy: 0.9533 - val_out_a_accuracy: 0.9540 - lr: 0.0010\n",
            "Epoch 29/200\n",
            "960/960 [==============================] - 19s 20ms/step - loss: 0.2581 - out_v_loss: 0.1308 - out_a_loss: 0.1273 - out_v_accuracy: 0.9458 - out_a_accuracy: 0.9472 - val_loss: 0.2430 - val_out_v_loss: 0.1243 - val_out_a_loss: 0.1186 - val_out_v_accuracy: 0.9499 - val_out_a_accuracy: 0.9533 - lr: 0.0010\n",
            "Epoch 30/200\n",
            "960/960 [==============================] - 19s 20ms/step - loss: 0.2465 - out_v_loss: 0.1252 - out_a_loss: 0.1213 - out_v_accuracy: 0.9477 - out_a_accuracy: 0.9493 - val_loss: 0.2379 - val_out_v_loss: 0.1213 - val_out_a_loss: 0.1166 - val_out_v_accuracy: 0.9519 - val_out_a_accuracy: 0.9531 - lr: 0.0010\n",
            "Epoch 31/200\n",
            "960/960 [==============================] - 19s 20ms/step - loss: 0.2433 - out_v_loss: 0.1226 - out_a_loss: 0.1207 - out_v_accuracy: 0.9489 - out_a_accuracy: 0.9492 - val_loss: 0.2283 - val_out_v_loss: 0.1115 - val_out_a_loss: 0.1168 - val_out_v_accuracy: 0.9567 - val_out_a_accuracy: 0.9535 - lr: 0.0010\n",
            "Epoch 32/200\n",
            "960/960 [==============================] - 20s 21ms/step - loss: 0.2432 - out_v_loss: 0.1216 - out_a_loss: 0.1215 - out_v_accuracy: 0.9505 - out_a_accuracy: 0.9496 - val_loss: 0.2207 - val_out_v_loss: 0.1151 - val_out_a_loss: 0.1056 - val_out_v_accuracy: 0.9545 - val_out_a_accuracy: 0.9583 - lr: 0.0010\n",
            "Epoch 33/200\n",
            "960/960 [==============================] - 19s 20ms/step - loss: 0.2362 - out_v_loss: 0.1197 - out_a_loss: 0.1165 - out_v_accuracy: 0.9499 - out_a_accuracy: 0.9517 - val_loss: 0.2275 - val_out_v_loss: 0.1183 - val_out_a_loss: 0.1092 - val_out_v_accuracy: 0.9534 - val_out_a_accuracy: 0.9555 - lr: 0.0010\n",
            "Epoch 34/200\n",
            "960/960 [==============================] - 19s 20ms/step - loss: 0.2329 - out_v_loss: 0.1166 - out_a_loss: 0.1163 - out_v_accuracy: 0.9521 - out_a_accuracy: 0.9521 - val_loss: 0.2219 - val_out_v_loss: 0.1142 - val_out_a_loss: 0.1077 - val_out_v_accuracy: 0.9551 - val_out_a_accuracy: 0.9572 - lr: 0.0010\n",
            "Epoch 35/200\n",
            "960/960 [==============================] - 19s 20ms/step - loss: 0.2267 - out_v_loss: 0.1128 - out_a_loss: 0.1139 - out_v_accuracy: 0.9535 - out_a_accuracy: 0.9526 - val_loss: 0.2177 - val_out_v_loss: 0.1141 - val_out_a_loss: 0.1036 - val_out_v_accuracy: 0.9561 - val_out_a_accuracy: 0.9597 - lr: 0.0010\n",
            "Epoch 36/200\n",
            "960/960 [==============================] - 18s 19ms/step - loss: 0.2235 - out_v_loss: 0.1132 - out_a_loss: 0.1103 - out_v_accuracy: 0.9532 - out_a_accuracy: 0.9546 - val_loss: 0.2183 - val_out_v_loss: 0.1117 - val_out_a_loss: 0.1066 - val_out_v_accuracy: 0.9559 - val_out_a_accuracy: 0.9587 - lr: 0.0010\n",
            "Epoch 37/200\n",
            "960/960 [==============================] - 20s 21ms/step - loss: 0.2231 - out_v_loss: 0.1138 - out_a_loss: 0.1093 - out_v_accuracy: 0.9542 - out_a_accuracy: 0.9547 - val_loss: 0.2163 - val_out_v_loss: 0.1089 - val_out_a_loss: 0.1075 - val_out_v_accuracy: 0.9569 - val_out_a_accuracy: 0.9590 - lr: 0.0010\n",
            "Epoch 38/200\n",
            "958/960 [============================>.] - ETA: 0s - loss: 0.2165 - out_v_loss: 0.1099 - out_a_loss: 0.1066 - out_v_accuracy: 0.9552 - out_a_accuracy: 0.9566"
          ]
        }
      ]
    }
  ]
}